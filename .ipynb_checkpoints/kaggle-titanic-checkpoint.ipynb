{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/users/engel/api/keys/heyengel-aws.json') as f:\n",
    "    data = json.load(f)\n",
    "    access_key = data['access-key'] \n",
    "    secret_access_key = data['secret-access-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_train = 's3://%s:%s@aws-s3-data/kaggle/titanic/train.csv' %(access_key,secret_access_key)\n",
    "link_test = 's3://%s:%s@aws-s3-data/kaggle/titanic/test.csv' %(access_key,secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"data/train.csv\")\n",
    "# test  = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.read_csv(link_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('s3a://aws-s3-data/kaggle/titanic/train.csv')\n",
    "test  = pd.read_csv('s3a://aws-s3-data/kaggle/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train.Cabin.str.split().str.get(-1).str[0]\n",
    "# train.Cabin.str.split(expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             A/5\n",
       "1              PC\n",
       "2        STON/O2.\n",
       "3          113803\n",
       "4          373450\n",
       "5          330877\n",
       "6           17463\n",
       "7          349909\n",
       "8          347742\n",
       "9          237736\n",
       "10             PP\n",
       "11         113783\n",
       "12           A/5.\n",
       "13         347082\n",
       "14         350406\n",
       "15         248706\n",
       "16         382652\n",
       "17         244373\n",
       "18         345763\n",
       "19           2649\n",
       "20         239865\n",
       "21         248698\n",
       "22         330923\n",
       "23         113788\n",
       "24         349909\n",
       "25         347077\n",
       "26           2631\n",
       "27          19950\n",
       "28         330959\n",
       "29         349216\n",
       "          ...    \n",
       "861         28134\n",
       "862         17466\n",
       "863           CA.\n",
       "864        233866\n",
       "865        236852\n",
       "866      SC/PARIS\n",
       "867            PC\n",
       "868        345777\n",
       "869        347742\n",
       "870        349248\n",
       "871         11751\n",
       "872           695\n",
       "873        345765\n",
       "874          P/PP\n",
       "875          2667\n",
       "876          7534\n",
       "877        349212\n",
       "878        349217\n",
       "879         11767\n",
       "880        230433\n",
       "881        349257\n",
       "882          7552\n",
       "883    C.A./SOTON\n",
       "884      SOTON/OQ\n",
       "885        382652\n",
       "886        211536\n",
       "887        112053\n",
       "888         W./C.\n",
       "889        111369\n",
       "890        370376\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.Ticket.str.split().str.get(0).str.extract\n",
    "train.Ticket.str.split()[0:].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train[train['Survived']==1][\"Age\"].mean(), \\\n",
    "train[train['Survived']==0][\"Age\"].mean(), \\\n",
    "test.Age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_data(titanic):\n",
    "\n",
    "    titanic = titanic.copy()\n",
    "    \n",
    "    titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "    titanic[\"Fare\"] = titanic[\"Fare\"].fillna(titanic[\"Fare\"].median())\n",
    "    titanic['Cabin'] = titanic['Cabin'].str.split().str.get(-1).str[0]\n",
    "    titanic['Ticket'] = titanic.Ticket.str.split()[0:].str[0]\n",
    "    \n",
    "    titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = -10\n",
    "    titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 10\n",
    "    \n",
    "    titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "    \n",
    "    titanic['Title'] = titanic['Name'].apply(lambda x: x.split(',')[1].split()[0])\n",
    "\n",
    "#     d = {'Mr.':'Mr', 'Mrs.':'Mrs', 'Miss.':'Miss', 'Master.':'Master', 'Don.':'Mr', 'Rev.':'Mr', 'Dr.':'Dr', 'Mme.':'Mrs',\n",
    "#        'Ms.':'Miss', 'Major.':'Mr', 'Lady.':'Miss', 'Sir.':'Mr', 'Mlle.':'Miss', 'Col.':'Mr', 'Capt.':'Mr', 'the':'Mr',\n",
    "#        'Jonkheer.':'Mr', 'Dona.':'Mrs'}\n",
    "    \n",
    "    d = {'Mr.':28, 'Mrs.':80, 'Miss.':50, 'Master.':28, 'Don.':40, 'Rev.':60, 'Dr.':60, 'Mme.':80,\n",
    "       'Ms.':50, 'Major.':60, 'Lady.':70, 'Sir.':40, 'Mlle.':50, 'Col.':60, 'Capt.':60, 'the':28,\n",
    "       'Jonkheer.':28, 'Dona.':70}\n",
    "\n",
    "    titanic['Title'].replace(d, inplace =True)\n",
    "    \n",
    "    colnames = ['Embarked','Cabin','Ticket']\n",
    "    for colname in colnames:\n",
    "        titanic[colname] = pd.Categorical(titanic[colname]).codes\n",
    "\n",
    "#     # Grab all the features that can be included in a Random Forest Regressor\n",
    "#     age_titanic = titanic[['Age','Fare','Ticket','Pclass','Cabin','Title']]\n",
    "\n",
    "#     # Split into sets with known and unknown Age values\n",
    "#     knownAge = age_titanic.loc[ (titanic.Age.notnull()) ]\n",
    "#     unknownAge = age_titanic.loc[ (titanic.Age.isnull()) ]\n",
    "    \n",
    "#     # All age values are stored in a target array\n",
    "#     y = knownAge.pop('Age').values\n",
    "  \n",
    "#     # All the other values are stored in the feature array\n",
    "#     X = knownAge.values\n",
    "    \n",
    "#     # Create and fit a model\n",
    "#     rtr = RandomForestRegressor(20)\n",
    "#     rtr.fit(X, y)\n",
    "    \n",
    "#     # Use the fitted model to predict the missing values\n",
    "#     predictedAges = rtr.predict(unknownAge.values[:, 1::])\n",
    "    \n",
    "#     # Assign those predictions to the full data set\n",
    "#     titanic.loc[ (titanic.Age.isnull()), 'Age' ] = predictedAges \n",
    "    \n",
    "    \n",
    "    # StandardScaler will subtract the mean from each value then scale to the unit variance\n",
    "#     scaler = StandardScaler()\n",
    "#     titanic['Age_scaled'] = scaler.fit_transform(titanic['Age'])\n",
    "#     titanic['Fare_scaled'] = scaler.fit_transform(titanic['Fare'])\n",
    "    \n",
    "    titanic.Age = titanic.Age/titanic.Age.max()\n",
    "    titanic.Fare = titanic.Fare/titanic.Fare.max()\n",
    "\n",
    "    titanic['AgeSex'] = titanic.Age * titanic.Sex\n",
    "    titanic['AgeSexFare'] = titanic.Age * titanic.Sex * titanic.Fare\n",
    "#     titanic['TitlePclass'] = titanic.Title * titanic.Pclass\n",
    "#     titanic['CabinPclass'] = titanic.Cabin * titanic.Pclass\n",
    "#     titanic['PclassSq'] = titanic.Pclass ** 2\n",
    "#     titanic['SexFare'] = titanic.Sex * titanic.Fare\n",
    "#     titanic[\"FamilySize\"] = titanic['Parch'] + titanic['SibSp']\n",
    "\n",
    "\n",
    "#     titanic.loc[(titanic[\"Sex\"] == \"female\") , \"Age\"] = \\\n",
    "#         titanic.loc[(titanic[\"Sex\"] == \"female\") , \"Age\"].fillna(28.34)\n",
    "#     titanic.loc[(titanic[\"Sex\"] == \"male\") , \"Age\"] = \\\n",
    "#         titanic.loc[(titanic[\"Sex\"] == \"male\") , \"Age\"].fillna(30.62)\n",
    "#         (titanic[titanic['Survived']==0][\"Age\"].mean())    \n",
    "    \n",
    "#     titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 1\n",
    "#     titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 2\n",
    "#     titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 3\n",
    "    \n",
    "    titanic.drop(titanic[['Name', \n",
    "#                           'Ticket', \n",
    "#                           'Cabin',\n",
    "#                           'Age',\n",
    "#                           'Sex',\n",
    "#                           'Fare',\n",
    "                          'SibSp',\n",
    "                          'Parch',\n",
    "#                           'Title',\n",
    "#                           'Pclass',\n",
    "                         ]], axis = 1, inplace=True)\n",
    "    \n",
    "    return titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train = train[train.Age > 0]\n",
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = clean_data(train)\n",
    "df_train = df.copy()\n",
    "df_train.drop('PassengerId', axis=1, inplace=True)\n",
    "df_test  = clean_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df_train.pop('Survived').values\n",
    "X = df_train.values\n",
    "X_test = df_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "train[train['Survived']==1][\"Age\"].hist(bins=20, label='survived')\n",
    "plt.title('Survived')\n",
    "plt.subplot(1,2,2)\n",
    "train[train['Survived']==0][\"Age\"].hist(bins=20)\n",
    "plt.title('Did not survive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(40, n_jobs=-1)\n",
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_rank = np.argsort(rf.feature_importances_)[::-1]\n",
    "feat_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.columns[feat_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(rf.feature_importances_,df_train.columns, columns = ['feature_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_features.sort_values('feature_value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = np.zeros((feat_rank.shape[0],2))\n",
    "for i in range(1,feat_rank.shape[0]+1):\n",
    "    features = [df_train.columns[feat_rank][x] for x in range(i)]\n",
    "    scores[i-1:] = (i,(cross_val_score(rf, df[features], df['Survived'], cv=10)).mean())\n",
    "scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(scores[:,:1],scores[:,1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [df_train.columns[feat_rank][x] for x in range(10)]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(rf, df[features], df['Survived'], cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), df_train.columns[indices])\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features = [df_train.columns[indices][x] for x in range(7)]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = ['AgeSex',\n",
    "#  'AgeSexFare',\n",
    "#  'TitleFare',\n",
    "#  'Fare',\n",
    "# #  'Sex',\n",
    "# #  'Age',\n",
    "#  'Pclass',\n",
    "#  'FamilySize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_train[features].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(model, train, test, features, filename):\n",
    "\n",
    "#     model.fit(train[features], train['Survived'])\n",
    "    predictions = model.predict(test[features])\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 6),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              'n_estimators': [10, 40, 50, 60],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, n_jobs=-1)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.grid_scores_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use a full grid over all parameters\n",
    "param_grid = {'max_depth': [3, 6, None],\n",
    "              'max_features': ['sqrt', 'log2', None],\n",
    "              'min_samples_split': [1, 2, 4, 6],\n",
    "              'min_samples_leaf': [2, 4, 6],\n",
    "              'bootstrap': [True, False],\n",
    "              'n_estimators': [30, 40, 50, 60],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, n_jobs=-1)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.grid_scores_)))\n",
    "report(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission(grid_search.best_estimator_,\n",
    "                        df, df_test, features, \"rf_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "0.79426\n",
    "['AgeSex', 'AgeSexFare', 'Fare', 'Sex', 'Pclass', 'Age']\n",
    "create_submission(RandomForestClassifier(\n",
    "                        bootstrap= True, \n",
    "                        min_samples_leaf= 3, \n",
    "                        n_estimators= 20, \n",
    "                        min_samples_split= 9, \n",
    "                        criterion= 'entropy', \n",
    "                        max_features= 4, \n",
    "                        max_depth= None)\n",
    "\n",
    "0.78469\n",
    "['AgeSex', 'AgeSexFare', 'Fare', 'Age', 'Pclass', 'Sex']\n",
    "create_submission(RandomForestClassifier(50, min_samples_split=4, min_samples_leaf=2), \\\n",
    "                  df, df_test, predictors, \"submission.csv\")\n",
    "0.76555\n",
    "['AgeSex', 'AgeSexFare', 'Fare', 'Age']\n",
    "create_submission(RandomForestClassifier(50, min_samples_split=4, min_samples_leaf=2), \\\n",
    "                  df, df_test, features, \"submission.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trees_accuracy = []\n",
    "for i in xrange(1,X.shape[1]):\n",
    "    rf = RandomForestClassifier(50, max_features = i, min_samples_split=4, min_samples_leaf=2)\n",
    "    rf.fit(X, y)\n",
    "    trees_accuracy.append(rf.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, X.shape[1]), trees_accuracy, '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('scaler', StandardScaler()), \n",
    "                     ('svc', SVC(kernel='linear'))])\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {'kernel':['linear','rbf'], \n",
    "              'C':np.linspace(.001,10,5),'degree':np.linspace(0,10,5)}\n",
    "\n",
    "gsCV = GridSearchCV(estimator=pipeline.steps[1][1],\n",
    "                    param_grid=parameters,scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pipeline.steps[0][1].fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsCV.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsCV.grid_scores_, gsCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean: 0.78151, std: 0.03323, params: {'C': 25.00075, 'degree': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_submission(model, train, test, features, filename):\n",
    "\n",
    "    model.fit(train[features], train['Survived'])\n",
    "    predictions = model.predict(test[features])\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_features = [df_train.columns[feat_rank][x] for x in range(8)]\n",
    "svm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission(Pipeline([('scaler', StandardScaler()),\n",
    "                    ('svc', SVC(kernel='rbf', C=2.5, degree=2.5))]), \\\n",
    "                  df, df_test, svm_features, \"svm_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_train\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdb = GradientBoostingClassifier(\n",
    "                n_estimators=3000,\n",
    "                learning_rate = 0.01, \n",
    "                max_depth = 4,\n",
    "                max_features = 0.1,\n",
    "                min_samples_leaf = 17)\n",
    "gdb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_rank = np.argsort(gdb.feature_importances_)[::-1]\n",
    "feat_rank\n",
    "df_train.columns[feat_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boost_features = [df_train.columns[feat_rank][x] for x in range(8)]\n",
    "boost_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train[boost_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_train[boost_features]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "              'max_depth': [4, 6],\n",
    "              'min_samples_leaf': [3, 5, 9, 17],\n",
    "              'max_features': [1.0, 0.3, 0.1]}\n",
    "gdb_grid = GradientBoostingClassifier(n_estimators=6000)\n",
    "gs_cv = GridSearchCV(gdb_grid, param_grid).fit(X,y)\n",
    "\n",
    "gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_cv.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "BEST PARAMS\n",
    "{'learning_rate': 0.01,\n",
    " 'max_depth': 4,\n",
    " 'max_features': 0.1,\n",
    " 'min_samples_leaf': 17}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission(GradientBoostingClassifier(\n",
    "                n_estimators=3000,\n",
    "                learning_rate = 0.01, \n",
    "                max_depth = 4,\n",
    "                max_features = 0.1,\n",
    "                min_samples_leaf = 9),\n",
    "                df, df_test, boost_features, \"gdboost_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_train\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(\n",
    "                n_estimators=3000,\n",
    "                learning_rate = 0.01)\n",
    "ada.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_rank = np.argsort(ada.feature_importances_)[::-1]\n",
    "ada_features = [df_train.columns[feat_rank][x] for x in range(6)]\n",
    "ada_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_train[ada_features]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [1, 0.1, 0.05, 0.02, 0.01]}\n",
    "\n",
    "ada_grid = AdaBoostClassifier(n_estimators=6000)\n",
    "ada_cv = GridSearchCV(ada_grid, param_grid).fit(X,y)\n",
    "\n",
    "ada_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission(AdaBoostClassifier(\n",
    "                n_estimators=3000,\n",
    "                learning_rate = 0.01),\n",
    "                df, df_test, ada_features, \"adaboost_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
